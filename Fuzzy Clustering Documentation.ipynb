{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Logic Clustering\n",
    "\n",
    "A common problem for database administrators is that of grouping unique entities when the integrity of the records is questionable. In other words, names might be missing or mispelled, records might be incomplete but still individually identifiable using human intuition. With tens of thousands of records to identity, human intuition must be supported with additional technical muscle. One approach to this problem is to apply Levenshtein distance across the fields of two records to determine if they are related. Groups will be formed by similarity and weights will be applied to the data fields according to their value to us (e.g. SNN is more identifiable than suffix or zip code).\n",
    "\n",
    "## <a name=\"TOC\"></a> Table of Contents:\n",
    "---\n",
    "1. [Data Set](#data)\n",
    "2. [Description of Algorithm](#description)\n",
    "  1. [Card Analogy](#cards)\n",
    "  2. [Detailed Description](#detailed)\n",
    "3. [Proof of Process](#proof)\n",
    "4. [Development of Methods](#methods)\n",
    "5. [Full Algorithm](#algorithm)\n",
    "  1. [Instantiation](#instantiate)\n",
    "  2. [Iteration](#iterate)\n",
    "  3. [Pull Group Records](#pull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- CONFIGURE ENVIRONMENT -------------------- #\n",
    "\n",
    "# Environment hard reset\n",
    "%reset -f\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard math libraries\n",
    "import math as math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "%matplotlib inline\n",
    "\n",
    "# SQL-similar commands\n",
    "from collections import Counter\n",
    "\n",
    "# System level control\n",
    "import sys\n",
    "\n",
    "# Support for progress bar\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Levenshtein fuzzy comparisons\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Configure paths\n",
    "from pathlib import Path\n",
    "data_path = Path('Data')\n",
    "fig_path = Path('PyFigures')\n",
    "\n",
    "# Setup log file\n",
    "f = open('Logs.txt', 'w').close()\n",
    "filename = 'Logs.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"data\"></a> [Data Set](#TOC)\n",
    "---\n",
    "\n",
    "The synthesized data that we will be studying comes in the form of records. I have simulated data fields with names, addresses and SSNs. There are multiple groups within this dataset and therefore multiple groups should be identified by our algorithm. Many of these identities are one to one such that a single identity has a single record but several identities are described by several records in a one to many scenario. It is my hope that my algorithm will successfully identify these relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRST</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>LAST</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>SSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARVEY</td>\n",
       "      <td>B</td>\n",
       "      <td>MILK</td>\n",
       "      <td>1930 RECRUIT YOU AVE</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>314159265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARVEY</td>\n",
       "      <td>B</td>\n",
       "      <td>MILK</td>\n",
       "      <td>1930 RECRUIT YOU AVE</td>\n",
       "      <td>SF</td>\n",
       "      <td>CA</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>314159265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>MLLK</td>\n",
       "      <td>1930 RECRUIT YOU AVE</td>\n",
       "      <td>SF</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314159265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930 RECRUIT U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RICK</td>\n",
       "      <td>P</td>\n",
       "      <td>SANCHEZ</td>\n",
       "      <td>EARTH C-137</td>\n",
       "      <td>TACOMA</td>\n",
       "      <td>WA</td>\n",
       "      <td>98402.0</td>\n",
       "      <td>929601596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PYOTR</td>\n",
       "      <td>I</td>\n",
       "      <td>TCHAIKOVSKY</td>\n",
       "      <td>1840 N ST PETER</td>\n",
       "      <td>VOTKINSK</td>\n",
       "      <td>GA</td>\n",
       "      <td>11893.0</td>\n",
       "      <td>155633999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RUPERT</td>\n",
       "      <td>L</td>\n",
       "      <td>DONLEY</td>\n",
       "      <td>518 EVEREST BLVD</td>\n",
       "      <td>UDEMY</td>\n",
       "      <td>FL</td>\n",
       "      <td>12358.0</td>\n",
       "      <td>123789235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELEANOR</td>\n",
       "      <td>P</td>\n",
       "      <td>TWINE</td>\n",
       "      <td>7878 SEVEN EIGHT</td>\n",
       "      <td>SMALL TOWN</td>\n",
       "      <td>LA</td>\n",
       "      <td>26916.0</td>\n",
       "      <td>148978105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MICHELL</td>\n",
       "      <td>M</td>\n",
       "      <td>MENENDEZ</td>\n",
       "      <td>58 CLOUDLESS SKY WAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32156.0</td>\n",
       "      <td>203254687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHARLES</td>\n",
       "      <td>F</td>\n",
       "      <td>KANE</td>\n",
       "      <td>794 BROKEN HOME AVE</td>\n",
       "      <td>ROSEBUD</td>\n",
       "      <td>PA</td>\n",
       "      <td>56465.0</td>\n",
       "      <td>489324789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HOLDEN</td>\n",
       "      <td>K</td>\n",
       "      <td>CAULFIELD</td>\n",
       "      <td>79 IRONICAL DRIVE</td>\n",
       "      <td>INNOCENCE</td>\n",
       "      <td>PA</td>\n",
       "      <td>45687.0</td>\n",
       "      <td>102354548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATTICUS</td>\n",
       "      <td>J</td>\n",
       "      <td>FINCH</td>\n",
       "      <td>1930 JUSTICE AVENUE</td>\n",
       "      <td>MAYCOMB</td>\n",
       "      <td>AL</td>\n",
       "      <td>36460.0</td>\n",
       "      <td>121611201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KIT</td>\n",
       "      <td>H</td>\n",
       "      <td>SHARBER</td>\n",
       "      <td>PARADISE PLACE</td>\n",
       "      <td>ALMA</td>\n",
       "      <td>OR</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>485943315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>MUAD'DIB</td>\n",
       "      <td>ATREIDES</td>\n",
       "      <td>314 PALACIAL ST</td>\n",
       "      <td>CALADAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>111555888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>MAWDIB</td>\n",
       "      <td>ATRAYDEZ</td>\n",
       "      <td>PALACIAL ST</td>\n",
       "      <td>CALADAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>111555888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>MAWDIB</td>\n",
       "      <td>ATRAYDEZ</td>\n",
       "      <td>314 PALACIAL STREET</td>\n",
       "      <td>CALIDAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>111555888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MICHEAL</td>\n",
       "      <td>J</td>\n",
       "      <td>BURRY</td>\n",
       "      <td>20400 STEVENS CREEK BLVD</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>95014.0</td>\n",
       "      <td>158971324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MIKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BURRY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158971324.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIRST    MIDDLE         LAST                   ADDRESS           CITY  \\\n",
       "0    HARVEY         B         MILK      1930 RECRUIT YOU AVE  SAN FRANCISCO   \n",
       "1    HARVEY         B         MILK      1930 RECRUIT YOU AVE             SF   \n",
       "2         H         B         MLLK      1930 RECRUIT YOU AVE             SF   \n",
       "3         H       NaN          NaN            1930 RECRUIT U            NaN   \n",
       "4      RICK         P      SANCHEZ               EARTH C-137         TACOMA   \n",
       "5     PYOTR         I  TCHAIKOVSKY           1840 N ST PETER       VOTKINSK   \n",
       "6    RUPERT         L       DONLEY          518 EVEREST BLVD          UDEMY   \n",
       "7   ELEANOR         P        TWINE          7878 SEVEN EIGHT     SMALL TOWN   \n",
       "8   MICHELL         M     MENENDEZ      58 CLOUDLESS SKY WAY            NaN   \n",
       "9   CHARLES         F         KANE       794 BROKEN HOME AVE        ROSEBUD   \n",
       "10   HOLDEN         K    CAULFIELD         79 IRONICAL DRIVE      INNOCENCE   \n",
       "11  ATTICUS         J        FINCH       1930 JUSTICE AVENUE        MAYCOMB   \n",
       "12      KIT         H      SHARBER            PARADISE PLACE           ALMA   \n",
       "13     PAUL  MUAD'DIB     ATREIDES           314 PALACIAL ST        CALADAN   \n",
       "14     PAUL    MAWDIB     ATRAYDEZ               PALACIAL ST        CALADAN   \n",
       "15     PAUL    MAWDIB     ATRAYDEZ       314 PALACIAL STREET        CALIDAN   \n",
       "16  MICHEAL         J        BURRY  20400 STEVENS CREEK BLVD      CUPERTINO   \n",
       "17     MIKE       NaN        BURRY                       NaN      CUPERTINO   \n",
       "\n",
       "   STATE      ZIP          SSN  \n",
       "0     CA  18896.0  314159265.0  \n",
       "1     CA  18896.0  314159265.0  \n",
       "2     CA      NaN  314159265.0  \n",
       "3    NaN  18896.0          NaN  \n",
       "4     WA  98402.0  929601596.0  \n",
       "5     GA  11893.0  155633999.0  \n",
       "6     FL  12358.0  123789235.0  \n",
       "7     LA  26916.0  148978105.0  \n",
       "8    NaN  32156.0  203254687.0  \n",
       "9     PA  56465.0  489324789.0  \n",
       "10    PA  45687.0  102354548.0  \n",
       "11    AL  36460.0  121611201.0  \n",
       "12    OR  10002.0  485943315.0  \n",
       "13    CA  15587.0  111555888.0  \n",
       "14    CA  15587.0  111555888.0  \n",
       "15    CA  15587.0  111555888.0  \n",
       "16    CA  95014.0  158971324.0  \n",
       "17    CA      NaN  158971324.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- IMPORT DATA -------------------- #\n",
    "\n",
    "# Import from CSV\n",
    "Data = pd.read_csv(data_path / 'SyntheticData.csv')\n",
    "\n",
    "# See all data\n",
    "Data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- DATA PREPROCESSING -------------------- #\n",
    "\n",
    "# Replace missing with NaN object\n",
    "Data.fillna(np.nan)\n",
    "\n",
    "# Make sure NaNs are identifiable\n",
    "math.isnan( Data.iloc[3]['MIDDLE'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"description\"></a> [Description of Algorithm](#TOC)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"cards\"></a> [Card Analogy](#description)\n",
    "\n",
    "My process for clustering will follow a standard card analogy. Imagine that we have a deck of cards and we wish to cluster them. By what? Suit? Royalty? Value? We say that we want to sort by suit but that the symbols for the suite have been obscured and disfigured. We know that hearts and diamonds, clubs and spades look similar but that there is a way to compare their similarity. Our process follows:\n",
    "\n",
    "0. Throw one card on the table and make it a group\n",
    "\n",
    "1. Select the next card\n",
    "\n",
    "2. Compare suits\n",
    "  1. If the new suit is sufficiently similar to an existing group then it joins the group that it is most similar to\n",
    "  2. If the new suit it not sufficiently similar to any existing group then it becomes its own group\n",
    "  \n",
    "3. Are there more cards in the deck?\n",
    "  1. Yes, go to 1.\n",
    "  2. No, end.\n",
    "\n",
    "This process ensures that a new group can only be formed by failing to belong to an existing group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"detailed\"></a> [Detailed Description](#description)\n",
    "\n",
    "#### Weighted Average\n",
    "\n",
    "Obviously, the card analogy does not entirely apply to the specifics of this problem. We have records with features (entries for a column) to identify them, some of which matter more to us than others for the purpose of identification.\n",
    "\n",
    "$$\n",
    "R_n = \\{ \\; f_0, f_1, f_N \\; \\}\n",
    "$$\n",
    "\n",
    "We express our system of priority by assigning weights to each feature by order of significance, like so:\n",
    "\n",
    "$$\n",
    "\\vec{ \\omega } = \\omega_0 + \\omega_1 + \\omega_N = \\sum_{n = 0}^{N} \\omega_n = 1.0\n",
    "$$\n",
    "\n",
    "Individual features of a record can be compared to the features of another record using Levenshtein distance. A ratio can be obtained which refects the percentage of similarity between the features. To express the similarity between the records however, we must apply the weights to the individual feature similarities. We can find the similarity $\\text{s}$:\n",
    "\n",
    "$$\n",
    "R_a = \\{ \\; f_{a0}, f_{a1}, ... \\; f_{aN} \\; \\} \\\\\n",
    "R_b = \\{ \\; f_{b0}, f_{b1}, ... \\; f_{bN} \\; \\} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{s} = \\omega_0 \\cdot \\text{Lev}( f_{a0}, f_{b0} ) \\; + \\; \\omega_1 \\cdot \\text{Lev}( f_{a1}, f_{b1} ) \\; + \\; ... \\; \\omega_N \\cdot \\text{Lev}( f_{aN}, f_{bN} )\n",
    "$$\n",
    "\n",
    "If $R_a$ is an existing group unto itself and $\\text{s}$ is greater than some threshhold big $\\text{S}$ then $R_b$ joins the group for $R_a$. Then a new record $R_c$ is compared to the center of $R_a$ (more on this later). The process repeats.\n",
    "\n",
    "However, if $\\text{s} < \\text{S}$, then $R_b$ becomes its own group. Then record $R_c$ is compared to records $R_a$ and $R_b$ and the process repeats.\n",
    "\n",
    "#### Weight Adjustment\n",
    "\n",
    "If a record has missing features, then the algorithm suffers a statistical nightmare. For example, imagine that we have two records $R_a$ and $R_b$ with four features which are equal in all respects except for one: $f_{a2} = \\text{NaN} \\neq f_{b2}$. If all weights are adjusted equally, then the best similarity that these records could obtain would be a 75%, which might be too low to exceed the threshhold. If we want these records to be equated, then we must either lower our standards of adjust the weights, but how?\n",
    "\n",
    "When a feature is missing, the algorithm drops the feature from the comparison and adjusts the weights while preserving the biasing. Say that feature number 2 is missing, then let $\\vec{ \\omega_{A} }$ represent the adjusted weights:\n",
    "\n",
    "$$\n",
    "\\text{Let} \\; \\vec{ \\omega } = [ \\omega_0, \\omega_1, \\omega_2, \\omega_3 ] \\; \\text{s.t.} \\; \\sum_{n = 0}^{N} \\omega_n = 1.0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{ \\omega_{A} } = [ \\omega_0, \\omega_1, 0, \\omega_3 ] \\longrightarrow [ \\frac{\\omega_0}{\\omega_0 + \\omega_1+ \\omega_3}, \\frac{\\omega_1}{\\omega_0 + \\omega_1+ \\omega_3}, 0, \\frac{\\omega_3}{\\omega_0 + \\omega_1+ \\omega_3} ]\n",
    "$$\n",
    "\n",
    "Using numeric values, let's say that $\\vec{ \\omega } = [ 0.20, 0.20, 0.50, 0.10 ]$ with feature number 2 missing, then:\n",
    "\n",
    "$$\n",
    "\\vec{ \\omega_{A} } = [ 0.20, 0.20, 0, 0.10 ] \\longrightarrow [ \\frac{0.20}{0.20 + 0.20 + 0.10}, \\frac{0.20}{0.20 + 0.20 + 0.10}, 0, \\frac{0.10}{0.20 + 0.20 + 0.10} ] = [ 0.40, 0.40, 0.20 ]\n",
    "$$\n",
    "\n",
    "The first and second weights maintain their proportionality to the final weight. Our algorithm has adjusted without loosing its assigned biases.\n",
    "\n",
    "#### The Most Human Human\n",
    "\n",
    "One issue facing our algorithm lies in the representation of groups. Storing groups programmatically is an issue unto itself, but comparing individual records against a group is the key challenge. With numeric data, there exists an idea of the centroid: an n-dimensional center of mass for a set of records. With text data, however, the centroid becomes more abstract.\n",
    "\n",
    "There are two approaches for finding the best representative of a group identity:\n",
    "\n",
    "1. Completeness - The record with the fewest missing fields.\n",
    "2. Similarity - The record that is the most common to the other records in the group.\n",
    "\n",
    "We will use approach 1 for groups with 2 or fewer records and approach 2 for groups with three or more records.\n",
    "\n",
    "#### Representing Hierarchy\n",
    "\n",
    "Another issue facing this system is how to store the hierarchy. My solution to this problem is to have a separate table with a column for group number, record number, and a flag for the centroid. Then we can quickly select a group number, obtain its records, and query the main dataframe for the record level details. We can manage the hierarchy efficiently without needing to pull the heavier records through the query, this approach should lower the computation requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"proof\"></a> [Proof of Process](#TOC)\n",
    "---\n",
    "\n",
    "Prior to developing sets of functions to execute my proposed algorithm, I want to develop the process to prove that it works in its raw form. Once I have established the viability of this route I can proceed to the next stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 \t: Missing []\n",
      "R7 \t: Missing []\n",
      "\n",
      "Original: \t[0.18, 0.15, 0.2, 0.05, 0.05, 0.1, 0.02, 0.25]\n",
      "Adjusted: \t[0.18 0.15 0.2  0.05 0.05 0.1  0.02 0.25]\n"
     ]
    }
   ],
   "source": [
    "# -------------------- SETUP WEIGHTS -------------------- #\n",
    "\n",
    "# Set biasing\n",
    "Omega = [ 0.18, 0.15, 0.20, 0.05, 0.05, 0.10, 0.02, 0.25 ]\n",
    "\n",
    "# Check that weights balance\n",
    "if np.sum( Omega ) != 1:\n",
    "    print('Weights are not in balance.')\n",
    "\n",
    "# Select two records\n",
    "#rec_ind = range( 0, len(data) )\n",
    "rec_ind = [ 1, 7 ]\n",
    "\n",
    "# -------------------- MISSING FEATURES -------------------- #\n",
    "\n",
    "# Check for null in each record\n",
    "for i in range( 0, len(rec_ind) ):\n",
    "    \n",
    "    # Find true indexes\n",
    "    true_ind = np.where( Data.iloc[ rec_ind[i] ].isnull().values == True )\n",
    "\n",
    "    # Assign status\n",
    "    status = 'Missing {}'.format( *true_ind )\n",
    "    \n",
    "    # Print record null status\n",
    "    print(\"R{} \\t: {}\".format(rec_ind[i], status) )\n",
    "    \n",
    "# Add a blank line\n",
    "print('')\n",
    "    \n",
    "# -------------------- ADJUST WEIGHTS -------------------- #\n",
    "\n",
    "# Copy and print normal weights\n",
    "Omega_A = Omega.copy()\n",
    "print('Original: \\t{}'.format( Omega ) )\n",
    "\n",
    "# Zero out missing indexes\n",
    "for i in true_ind[0]:\n",
    "    Omega_A[ i ] = 0\n",
    "    \n",
    "# Divide the weights by the sum of the non-zero weights, print results\n",
    "Omega_A = Omega_A / round( np.sum( [ Omega_A[i] for i in np.nonzero( Omega_A )[0] ] ), 20 )\n",
    "print('Adjusted: \\t{}'.format( Omega_A ))\n",
    "\n",
    "# Check that the weights balance out\n",
    "if not math.isclose( np.sum( Omega_A ), 1, abs_tol = 1e-100 ):\n",
    "    print('Weights are not in balance.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the weights are adjusting properly and the proportionality is preserved but now we must run the cummulative product of the Levenshtein distance and the adjusted weights to determine which records are similar to which records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lev Ratios: [31.  0. 22. 22. 17. 50. 57. 55.]\n",
      "Similarity: 31.82\n"
     ]
    }
   ],
   "source": [
    "# -------------------- RUN SIMILARITY -------------------- #\n",
    "\n",
    "# Set big S\n",
    "S = 75\n",
    "\n",
    "# Instantiate s\n",
    "s = np.array([])\n",
    "\n",
    "# Run comparison\n",
    "for j in range(0, len(Data.columns)):\n",
    "    s = np.append(s, fuzz.ratio( Data.iloc[ rec_ind[0] ].apply(str)[j], Data.iloc[ rec_ind[1] ].apply(str)[j] ) )\n",
    "    \n",
    "# Print LEV({}) results\n",
    "print( 'Lev Ratios: {}'.format(s) )\n",
    "\n",
    "# Linear product with adjusted weights\n",
    "s = np.inner( s, Omega_A )\n",
    "print( 'Similarity: {}'.format(s) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the missing feature has scored a zero on the similarity, identical records have been assigned a perfect Levenshtein ratio, and non-identical records have scored somewhere in between. This is as expected and the inner product of the ratios with the weights yields the similarity score that we have been looking for. Now we must decide if the individual record belongs with the group representative (centroid) or belongs as a record unto itself.\n",
    "\n",
    "We will pretend, for simplicity sake, that the first record in the comparison was a group centroid and that it was in the Groups dataframe the whole time as the only existing group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Record Number</th>\n",
       "      <th>Centroid Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group Number  Record Number  Centroid Flag\n",
       "0             0              1           True\n",
       "1             1              7           True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- DETERMINE GROUPING -------------------- #\n",
    "\n",
    "# Create Groups dataframe template\n",
    "grp_col = [ 'Group Number', 'Record Number', 'Centroid Flag' ]\n",
    "#Groups = pd.DataFrame( columns = grp_col )\n",
    "\n",
    "# Add the first record and pretend it was a group leader this whole time\n",
    "Groups = pd.DataFrame( data = { grp_col[0] : 0, grp_col[1] : rec_ind[0], grp_col[2] : True }, index = {0} )\n",
    "\n",
    "# If the record belong in the group\n",
    "if s >= S:\n",
    "    # Find group number for the record being tested\n",
    "    grp_no = Groups.loc[ Groups[ Groups.columns[1] ] == rec_ind[0] ][ Groups.columns[0] ].values[0]\n",
    "    \n",
    "    # Save record number under consideration\n",
    "    rec_no = rec_ind[1]\n",
    "    \n",
    "    # Create temp record for append\n",
    "    Record = pd.DataFrame(data = { grp_col[0] : grp_no, grp_col[1] : rec_no, grp_col[2] : False }, index = {0})\n",
    "    Groups = Groups.append( Record, ignore_index = True )\n",
    "\n",
    "# Otherwise make the record a new group\n",
    "else:\n",
    "    # Assign a new group number\n",
    "    grp_no = Groups[ Groups.columns[0] ].values.max() + 1\n",
    "    \n",
    "    # Save record number \n",
    "    rec_no = rec_ind[1]\n",
    "    \n",
    "    # Create temp record for append\n",
    "    Record = pd.DataFrame(data = { grp_col[0] : grp_no, grp_col[1] : rec_no, grp_col[2] : True }, index = {0})\n",
    "    Groups = Groups.append( Record, ignore_index = True )\n",
    "\n",
    "# Print results\n",
    "Groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, I have tested cases for high and low similarity and the resulting group logic is as expected. I can confidently claim that the system is working and that the concept has been proven valid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"methods\"></a> [Development of Methods](#TOC)\n",
    "---\n",
    "\n",
    "Now that the concept behind the algorithm has been validated, I can break the algorithm into discrete functions to improve the efficiency and safety of the process. These functions can be independently validated and ultimately sewn together for the final algorithm.\n",
    "\n",
    "### <a name=\"TOM\"></a> Table of Methods:\n",
    "---\n",
    "* [Iterator](#iterator) - Returns (opt-destructive) a record from a dataframe as a series.\n",
    "* [Adjust Weights](#adjust_weights) - Returns adjusted weights for two specific records.\n",
    "* [Centroid Iterator](#centroid_iterator) - Returns centroid record for a specific group number.\n",
    "* [Score Similarity](#score_similarity) - Returns the similarity between two records. \n",
    "* [Score Against Groups](#score_against_groups) - Returns the similarities between a record and each centroid.\n",
    "* [Centroid Assessment](#centroid_assessment) - Evaluates existing groups to elect new centroids.\n",
    "* [Append to Groups](#append_to_groups) - Adds a record to the groups dataframe.\n",
    "* [Progress Bar](#progress) - Functions to support the progress bar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP NUMBER</th>\n",
       "      <th>RECORD NUMBER</th>\n",
       "      <th>CENTROID FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GROUP NUMBER  RECORD NUMBER  CENTROID FLAG\n",
       "0              0              0              1\n",
       "1              0              1              0\n",
       "2              1              2              1\n",
       "3              2              3              1\n",
       "4              3              4              1\n",
       "5              4             13              1\n",
       "6              4             14              0\n",
       "7              4             15              0\n",
       "8              5             12              1\n",
       "9              6             16              0\n",
       "10             6             17              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- SET GLOBAL VARS ----- #\n",
    "\n",
    "# Omega bias preferences\n",
    "Omega = [ 0.18, 0.15, 0.20, 0.05, 0.05, 0.10, 0.02, 0.25 ]\n",
    "\n",
    "# Set big S\n",
    "S = 75\n",
    "\n",
    "# ----- SETUP LOGS ----- #\n",
    "\n",
    "filename = 'Logs.txt'\n",
    "logs = open(filename, 'w').close()\n",
    "logs = open(filename, 'a')\n",
    "\n",
    "# ----- COPY OF DATASET ----- #\n",
    "\n",
    "Dataset = Data.copy()\n",
    "\n",
    "# ----- SIMULATE GROUPS ----- #\n",
    "\n",
    "# Fake data\n",
    "fake_groups = [ 0, 0, 1, 2, 3, 4, 4, 4, 5, 6, 6 ]\n",
    "fake_record = [ 0, 1, 2, 3, 4, 13, 14, 15, 12, 16, 17 ]\n",
    "fake_roles  = [ True, False, True, True, True, True, False, False, True, False, True ]\n",
    "\n",
    "# Template columns\n",
    "grp_col = [ 'GROUP NUMBER', 'RECORD NUMBER', 'CENTROID FLAG' ]\n",
    "\n",
    "# Form data for simulation\n",
    "Groups = pd.DataFrame( np.transpose( np.array([ fake_groups, fake_record, fake_roles ]) ), columns = grp_col )\n",
    "Groups.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"iterator\"></a> [Iterator](#methods)\n",
    "\n",
    "This function operates as an iterator for any data frame. By calling this function, we pop a record from the dataframe and return it as a series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ITERATE RECORDS FROM THE DECK ----- #\n",
    "\n",
    "def iterator( df, destruct, verb ):\n",
    "    \"\"\"Returns (opt-destructive) a record from a dataframe as a series.\"\"\"\n",
    "    \n",
    "    # Verbosity and logs\n",
    "    if verb:\n",
    "        print('Iterating.')\n",
    "    \n",
    "    # Copy the last record in the deck\n",
    "    try:\n",
    "        next_record = df.iloc[ len(df)-1 ].copy()\n",
    "    except:\n",
    "        print('ERROR: ', sys.exc_info()[0], 'in iterate.')\n",
    "    \n",
    "    # Pop the last record from the deck\n",
    "    if destruct: df.drop( df.index[[next_record.name]], inplace = True )\n",
    "    \n",
    "    # Return next record\n",
    "    return next_record\n",
    "    \n",
    "# <----- DEMO -----> #\n",
    "\n",
    "# # Print a card using iterate\n",
    "# card = iterator( Dataset, False, False )\n",
    "# print( '{}: \\t{} {}'.format(i, card.FIRST, card.LAST) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"adjust_weights\"></a> [Adjust Weights](#methods)\n",
    "\n",
    "Here we take in the records for comparison and determine what weights must be dropped from the normal weights to insure that the bias is conserved but that the missing values do not eliminate the possibility for a match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ADJUST WEIGHTS FOR MISSING VALUES ----- #\n",
    "\n",
    "def adjust_weights( Norm, RA, RB, verb ):\n",
    "    \"\"\"Returns adjusted weights for two specific records.\"\"\"\n",
    "    \n",
    "    # ----- MISSING FEATURES ----- #\n",
    "\n",
    "    # Check for null in each record\n",
    "\n",
    "    # Find true indexes\n",
    "    missing_ind_RA = list(np.where( RA.isnull().values == True )[0])\n",
    "    if missing_ind_RA: \n",
    "        if verb:\n",
    "            print('RA #{} \\t: Missing {}'.format( RA.name, missing_ind_RA ) )\n",
    "\n",
    "    # Find missing indexes within Group\n",
    "    missing_ind_RB = list(np.where( RB.isnull().values == True )[0])\n",
    "    if missing_ind_RB:\n",
    "        if verb:\n",
    "            print('Record #{} \\t: Missing {}'.format( RB.name, missing_ind_RB ) )\n",
    "\n",
    "    # Combine lists of missing indexes\n",
    "    missing_ind = missing_ind_RA + missing_ind_RB\n",
    "\n",
    "    # Copy normal weights\n",
    "    Omega_A = Norm.copy()\n",
    "        \n",
    "    # ----- ADJUSTMENT ----- #\n",
    "\n",
    "    # Zero out missing indexes\n",
    "    for i in missing_ind:\n",
    "        Omega_A[ i ] = 0\n",
    "        \n",
    "    # Speak if adjusting weights\n",
    "    if missing_ind:\n",
    "        if verb:\n",
    "            print('Adjusting weights.')\n",
    "            \n",
    "    # Divide the weights by the sum of the non-zero weights, print results\n",
    "    Omega_A = list(Omega_A / round( np.sum( [ Omega_A[i] for i in np.nonzero( Omega_A )[0] ] ), 20 ))\n",
    "    \n",
    "    # Speak if adjusting weights\n",
    "    if missing_ind:\n",
    "        if verb:\n",
    "            print('Omega_A : {}'.format(Omega_A) )\n",
    "            \n",
    "    # Check that the weights balance out\n",
    "    if not math.isclose( np.sum( Omega_A ), 1, abs_tol = 1e-100 ):\n",
    "        if verb:\n",
    "            print('Weights are not in balance.')\n",
    "        return -1\n",
    "\n",
    "    # Close logs\n",
    "    logs.close()\n",
    "    \n",
    "    # Return next record\n",
    "    return Omega_A\n",
    "\n",
    "# <----- DEMO -----> #\n",
    "\n",
    "# RA = Dataset.iloc[7]\n",
    "# RB = Dataset.iloc[8]\n",
    "# Omega_A = adjust_weights( Omega, RA, RB, True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"centroid_iterator\"></a> [Centroid Iterator](#methods)\n",
    "\n",
    "When running the comparison system, we are looking to compare new records from the deck against the most representative record from each group. This is conceptually similar to the centroid from the K-Means algorithm. This function iterates through the centroids and returns its corresponding record. This method is not just a function of its own. Rather, it is a demonstration of how the process will operate. The function itself is essentially the [Iterator](#iterator) function without the destruct option and with the added input of group number: call fifth group leader, then sixth, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ITERATE CENTROID RECORDS ----- #\n",
    "\n",
    "def centroid_iterator( df, grp_no, verb ):\n",
    "    \"\"\"Returns centroid record for a specific group number.\"\"\"\n",
    "    \n",
    "    # Speak if necessary\n",
    "    if verb: print( 'Calling group #{}.'.format(grp_no) )\n",
    "        \n",
    "    # Return record for grp_no\n",
    "    return df.iloc[ Groups.loc[ Groups[ Groups.columns[2] ] == True ].iloc[grp_no][ Groups.columns[1] ] ]\n",
    "    \n",
    "# <----- DEMO -----> #\n",
    "    \n",
    "# # Iterate through first n group centroids\n",
    "# for i in range(0, 2):\n",
    "#     print( list(group_iterator( i, True ).values) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"score_similarity\"></a> [Score Similarity](#methods)\n",
    "\n",
    "Now that we have a concise way to readjust the weights with respect to the missing elements in records, we can work on developing a concise function to assess their similarity. This function calls for [weight adjustment](#adjust_weights) as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SCORE SIMILARITY ----- #\n",
    "\n",
    "def score_similarity( df, RA, RB, verb ):\n",
    "    \"\"\"Returns the similarity between two records.\"\"\"\n",
    "    \n",
    "    # Speak if necessary\n",
    "    if verb: print( 'Scoring record #{} against #{}.'.format(RA.name, RB.name) )\n",
    "    \n",
    "    # Instantiate s\n",
    "    s = np.array([])\n",
    "    \n",
    "    # Run comparison feature for feature\n",
    "    for j in range(0, len(df.columns)):\n",
    "        s = np.append(s, fuzz.ratio( RA.apply(str)[j], RB.apply(str)[j] ) )\n",
    "\n",
    "    # Linear product with adjusted weights\n",
    "    s = np.inner( list(s), adjust_weights( Omega, RA, RB, verb ) )\n",
    "    if verb: print( 'Similarity: {}'.format(s) )\n",
    "    \n",
    "    # Return score\n",
    "    return s\n",
    "    \n",
    "# <----- DEMO -----> #\n",
    "\n",
    "# # Pull two records\n",
    "# RA = Dataset.iloc[7].copy()\n",
    "# RB = Dataset.iloc[8].copy()\n",
    "\n",
    "# # Score records\n",
    "# score_similarity( Dataset, RA, RB, True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"score_against_groups\"></a> [Score Against Groups](#methods)\n",
    "\n",
    "Here we can call the similarity score function in conjuction with the group and dataframe iterators. We will use the iterator non-destructively with the centroid iterator to demonstrate how a record can be popped off of the deck, assess for missing values, scored with Levenshtein Distance against each existing group.\n",
    "\n",
    "This function returns a list of scores. These scores represent the similarities between the card and each existing group centroid. The index of the max score links to the group number with which the score is associated. This makes it easier to debug the $s \\geq S$ decisions and ensures that the decisions logic is outside te purview of this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SCORE CARD AGAINST CENTROIDS ----- #\n",
    "\n",
    "def score_against_groups( df, card, verb ):\n",
    "    \"\"\"Returns the similarities between a record and each centroid.\"\"\"\n",
    "\n",
    "    # Instantiate scores list\n",
    "    scores = np.array([])\n",
    "\n",
    "    # Iterate through groups\n",
    "    for i in range(0, len( Groups.loc[ Groups[ Groups.columns[2] ] == True ] )):\n",
    "\n",
    "        # Pop ith group centroid record\n",
    "        GN = centroid_iterator( df, i, verb )\n",
    "\n",
    "        # Score card against ith group\n",
    "        s = score_similarity( df, card, GN, verb )\n",
    "            \n",
    "        # Append score to scores list\n",
    "        scores = np.append(scores, s)\n",
    "        \n",
    "    # Return scores list\n",
    "    return scores\n",
    "\n",
    "# <----- DEMO -----> #\n",
    "\n",
    "# # Setup\n",
    "# verb = True\n",
    "\n",
    "# # Pop card from deck\n",
    "# card = iterator( Dataset, False, verb )\n",
    "\n",
    "# # Score card v. centroids\n",
    "# scores = score_against_groups( Dataset, card, verb )\n",
    "# list(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"centroid_assessment\"></a> [Centroid Assessment](#methods)\n",
    "\n",
    "Within the K-means algorithm, the center of a cluster adjusts when new records are assigned. Similarly, we may create individual groups due to uniqueness or incompleteness and then find a more accurate representative for a given identity. Consequently, we must periodically reevaluate which records are centroids.\n",
    "\n",
    "In the *Representing Group Centers* notes I describe two measurements for determining the centroid of a group. If the number of records in a group is 2 or fewer then the centroid must be the most complete record: the record with the fewest missing values.* If a group has three or more records then we can take the inner similarity between such records and determine which record is most similar to the records within its set. This way we know that we have selected the best representative of the group.\n",
    "\n",
    "*Additionally, we could find which record has the longest strings, and is therefore the most detailed but this approach has its drawbacks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate groups\n",
    "    # Select a group\n",
    "        # 1 record\n",
    "            # Record is set to centroid\n",
    "        # 2 records\n",
    "            # Find the most complete record\n",
    "            # Tie?\n",
    "            # - YES - #\n",
    "                # Don't change the record centroid\n",
    "            # - NO - #\n",
    "                # Choose the winner as the centroid\n",
    "        # More than 2 records\n",
    "            # Find the inner similarities and completeness\n",
    "            # Select the similarity winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- CENTROID ASSESSMENT ----- #\n",
    "\n",
    "def centroid_assessment( df, verb ):\n",
    "    \"\"\"Evaluates existing groups to elect new centroids.\"\"\"\n",
    "    \n",
    "    # Speak if necessary\n",
    "    if verb: print('Reassigning centroids.')\n",
    "\n",
    "    # Iterate through groups\n",
    "    for i in range( 0, np.unique( Groups[ Groups.columns[0] ].values ).size - 1 ):\n",
    "\n",
    "        # Select the ith group of records\n",
    "        Group = Groups.loc[ Groups[ Groups.columns[0] ] == i ].copy()\n",
    "\n",
    "        # Only one record?\n",
    "        if len(Group) == 1:\n",
    "\n",
    "            # Assign that one record as the centroid\n",
    "            Groups.at[ Group.loc[ Group[ Group.columns[2] ] == 1 ].index[0], Group.columns[2] ] = 1\n",
    "\n",
    "        # Two records?\n",
    "        elif len(Group) == 2:\n",
    "\n",
    "            # Instantiate missing set\n",
    "            missing = np.array([])\n",
    "\n",
    "            # Find missing values for each record\n",
    "            for r in [0, 1]:\n",
    "                missing_r = list(np.where( df.iloc[ Group.iloc[r][ Group.columns[1] ] ].isnull().values == True )[0])\n",
    "                missing = np.append(missing, len(missing_r))\n",
    "\n",
    "            # If there are missing values, which one is missing the fewest features?\n",
    "            if sum( missing ) != 0:\n",
    "                # Find index of the most complete record\n",
    "                centroid = [ i for i, j in enumerate(missing) if j == min(missing) ]\n",
    "\n",
    "                # Dethrone the current centroid\n",
    "                Groups.at[ Group.loc[ Group[ Group.columns[2] ] == 1 ].index[0], Groups.columns[2] ] = 0\n",
    "\n",
    "                # Assign the most complete record as the centroid\n",
    "                Groups.at[ Group.iloc[ centroid ].index[0], Groups.columns[2] ] = 1\n",
    "\n",
    "        # More than 2 records\n",
    "        elif len(Group) > 2:\n",
    "\n",
    "            # Instantiate inner similarity set\n",
    "            inner_similarity = np.zeros(( len(Group) , len(Group) ))\n",
    "\n",
    "            # Score the similarities of each record\n",
    "            for rj in range( 0, len(Group) ):\n",
    "                for ri in range( 0, len(Group) ):\n",
    "                    inner_similarity[rj, ri] = score_similarity( df, df.iloc[ Group.iloc[rj][ Group.columns[1] ] ],\n",
    "                                                                df.iloc[ Group.iloc[ri][ Group.columns[1] ] ], False )\n",
    "\n",
    "            # Take the average of each column\n",
    "            candidate_score = np.array([])\n",
    "            for j in range( 0, len(inner_similarity) ):\n",
    "                candidate_score = np.append( candidate_score, np.average( inner_similarity[:, j] ) )\n",
    "\n",
    "            # Find the index of the record with the highest commonality\n",
    "            centroid = [ i for i, j in enumerate(candidate_score) if j == max(candidate_score) ]\n",
    "\n",
    "            # Dethrone the current centroid\n",
    "            Groups.at[ Group.loc[ Group[ Group.columns[2] ] == 1 ].index[0], Groups.columns[2] ] = 0\n",
    "\n",
    "            # Assign the most common record as the centroid\n",
    "            Groups.at[ Group.iloc[ centroid ].index[0], Groups.columns[2] ] = 1\n",
    "            \n",
    "        else:\n",
    "            print('ERROR: Perverse logic in centroid_assessment.')\n",
    "            \n",
    "# <----- DEMO -----> #\n",
    "\n",
    "# # Call\n",
    "# print(Groups)\n",
    "# centroid_assessment( Dataset, False )\n",
    "# print(Groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"append_to_groups\"></a> [Append to Groups](#methods)\n",
    "\n",
    "This function is called to edit the Groups dataframe. It receives a copy of the Groups dataframe and appends a new entry with the group number, record number and a centroid flag then it returns the altered copy. The function can only be called like so\n",
    "\n",
    "```\n",
    "Groups = append_to_groups( Groups, grp_no, rec_no, new, verb )\n",
    "```\n",
    "\n",
    "Otherwords changes will not be saved to the dataframe as this function only edits and returns a copy. If the record is being added as a new group then the `new` argument must be set to True so that the new group has a centroid. Otherwise, set the `new` argument to False to preserve the centroid of an existing group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending record #901 as a new group.\n"
     ]
    }
   ],
   "source": [
    "# ----- APPEND TO GROUPS ----- #\n",
    "\n",
    "def append_to_groups( df, grp_no, rec_no, new, verb ):\n",
    "    \"\"\"Adds a record to the groups dataframe.\"\"\"\n",
    "    \n",
    "    # Speak if necessary\n",
    "    if verb:\n",
    "        if new: print( 'Appending record #{} as a new group.'.format(rec_no) )\n",
    "        if not new: print( 'Appending record #{} to group #{}.'.format(rec_no, grp_no) )\n",
    "        \n",
    "    # Configure centroid flag\n",
    "    if new: centroid = 1\n",
    "    else: centroid = 0\n",
    "    \n",
    "    # Create temp record for append\n",
    "    Record = pd.DataFrame(data = { df.columns[0] : grp_no, df.columns[1] : rec_no, df.columns[2] : centroid }, index = {0})\n",
    "    df = df.append( Record, ignore_index = True )\n",
    "    \n",
    "    # Return changes\n",
    "    return df\n",
    "\n",
    "# <----- DEMO -----> #\n",
    "\n",
    "# Set group number\n",
    "grp_no = 1\n",
    "\n",
    "# Call function\n",
    "Groups = append_to_groups( Groups, grp_no, 901, True, True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP NUMBER</th>\n",
       "      <th>RECORD NUMBER</th>\n",
       "      <th>CENTROID FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GROUP NUMBER  RECORD NUMBER  CENTROID FLAG\n",
       "2              1              2              1\n",
       "11             1            901              1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for entries within group number\n",
    "Groups.loc[ Groups[ Groups.columns[0] ] == grp_no ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"progress\"></a> [Progress Bar](#methods)\n",
    "\n",
    "These functions are designed to support the operation of the progress bar, an ASCII-art graphical visual of the status of the clustering process. The clustering can be arduously slow, necessitating the development of a system to communicate the programs proximity to completion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- APPEND TO GROUPS ----- #\n",
    "\n",
    "# Theoretical process with intermediate output\n",
    "def process(ttime):\n",
    "    time.sleep( ttime )\n",
    "\n",
    "# Define progress bar functionality\n",
    "def update_progress(name, progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "        \n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = name + \": [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"algorithm\"></a> [Full Algorithm](#TOC)\n",
    "---\n",
    "\n",
    "Using the methods designed in the previous section, we now compile our work into a single cohesive system of iterating through the dataset, clustering, and returning the final results. The over arching process is described in more detail by the Lucid Chart diagrams.\n",
    "\n",
    "### <a name=\"AlgoStages\"></a> Algorithm Stages:\n",
    "---\n",
    "* [Instantiation](#instantiate)\n",
    "* [Iteration](#iterate)\n",
    "* [Pull Group Records](#pull)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"instantiate\"></a> [Instantiation](#AlgoStages)\n",
    "---\n",
    "\n",
    "Prior to executing the algorithm, we must take in user preferences and establish the algorithms necessary components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Record Number</th>\n",
       "      <th>Centroid Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group Number Record Number Centroid Flag\n",
       "0            0            17             1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- INSTANTIATE ---------- #\n",
    "\n",
    "# -----> PREFERENCES\n",
    "\n",
    "# Omega bias preferences\n",
    "Omega = [ 0.18, 0.15, 0.20, 0.05, 0.05, 0.10, 0.02, 0.25 ]\n",
    "\n",
    "# Set big S\n",
    "S = 75\n",
    "\n",
    "# Verbosity\n",
    "verb = False\n",
    "\n",
    "# -----> CREATE COPIES OF THE DATASET\n",
    "\n",
    "Master = Data.copy()\n",
    "Deck   = Data.copy()\n",
    "\n",
    "# -----> CREATE GROUP DATAFRAME\n",
    "\n",
    "# Template columns\n",
    "grp_col = [ 'Group Number', 'Record Number', 'Centroid Flag' ]\n",
    "\n",
    "# Form data for simulation\n",
    "Groups = pd.DataFrame( columns = grp_col )\n",
    "\n",
    "# -----> START FIRST GROUP\n",
    "\n",
    "# Pop from deck\n",
    "card = iterator( Deck, True, False )\n",
    "\n",
    "# Append card to Groups\n",
    "Groups.loc[0] = [ 0, card.name, 1 ]\n",
    "Groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"iterate\"></a> [Iteration](#AlgoStages)\n",
    "---\n",
    "\n",
    "After having set the stage for the algorithms execution, we can iterate through the deck and proceed with the clustering process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering: [####################] 100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Record Number</th>\n",
       "      <th>Centroid Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group Number Record Number Centroid Flag\n",
       "0             0            17             0\n",
       "1             0            16             1\n",
       "2             1            15             0\n",
       "3             1            14             1\n",
       "4             1            13             0\n",
       "5             2            12             1\n",
       "6             3            11             1\n",
       "7             4            10             1\n",
       "8             5             9             1\n",
       "9             6             8             1\n",
       "10            7             7             1\n",
       "11            8             6             1\n",
       "12            9             5             1\n",
       "13           10             4             1\n",
       "14           11             3             0\n",
       "15           11             2             1\n",
       "16           12             1             1\n",
       "17           12             0             0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- ITERATE THROUGH DECK ---------- #\n",
    "\n",
    "# Define the number of steps to completion\n",
    "number_of_elements = len(Deck)\n",
    "\n",
    "# Main loop\n",
    "for c in range( 0, len(Deck) ):\n",
    "\n",
    "    # Pop card from deck\n",
    "    card = iterator( Deck, True, False )\n",
    "    \n",
    "    # Speak if necessary\n",
    "    if verb: print( 'Card is record #{}'.format(card.name) )\n",
    "\n",
    "    # Obtain scores\n",
    "    scores = score_against_groups( Master, card, verb )\n",
    "\n",
    "    # Take the highest score information\n",
    "    max_score_ind = np.argmax( scores )\n",
    "\n",
    "    # Branch based on s > S?\n",
    "    if scores[ max_score_ind ] >= S:\n",
    "\n",
    "        # Append record to an existing group\n",
    "        Groups = append_to_groups( Groups, max_score_ind, card.name, False, verb )\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Append record as a new group\n",
    "        Groups = append_to_groups( Groups, np.max( Groups[ Groups.columns[0] ].values )+1, card.name, True, verb )\n",
    "        \n",
    "    # Reassess centroids\n",
    "    centroid_assessment( Master, verb )\n",
    "    \n",
    "    # Call to update progress bar\n",
    "    if not verb: update_progress('Clustering', c / number_of_elements)\n",
    "    \n",
    "# Complete progress bar\n",
    "if not verb: update_progress('Clustering', 1)\n",
    "\n",
    "# Print results\n",
    "Groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Record Number</th>\n",
       "      <th>Centroid Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group Number Record Number Centroid Flag\n",
       "2            1            15             0\n",
       "3            1            14             1\n",
       "4            1            13             0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Harness a specific group number\n",
    "Groups.loc[ Groups[ Groups.columns[0] ] == 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"pull\"></a> [Pull Group Records](#AlgoStages)\n",
    "---\n",
    "\n",
    "With the clustering hierarchy in place, we can now append the group labeling to the original data to see if our human intuition agrees with the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRST</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>LAST</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Group Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARVEY</td>\n",
       "      <td>B</td>\n",
       "      <td>MILK</td>\n",
       "      <td>1930 RECRUIT YOU AVE</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>314159265.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARVEY</td>\n",
       "      <td>B</td>\n",
       "      <td>MILK</td>\n",
       "      <td>1930 RECRUIT YOU AVE</td>\n",
       "      <td>SF</td>\n",
       "      <td>CA</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>314159265.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>MLLK</td>\n",
       "      <td>1930 RECRUIT YOU AVE</td>\n",
       "      <td>SF</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314159265.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930 RECRUIT U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RICK</td>\n",
       "      <td>P</td>\n",
       "      <td>SANCHEZ</td>\n",
       "      <td>EARTH C-137</td>\n",
       "      <td>TACOMA</td>\n",
       "      <td>WA</td>\n",
       "      <td>98402.0</td>\n",
       "      <td>929601596.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PYOTR</td>\n",
       "      <td>I</td>\n",
       "      <td>TCHAIKOVSKY</td>\n",
       "      <td>1840 N ST PETER</td>\n",
       "      <td>VOTKINSK</td>\n",
       "      <td>GA</td>\n",
       "      <td>11893.0</td>\n",
       "      <td>155633999.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RUPERT</td>\n",
       "      <td>L</td>\n",
       "      <td>DONLEY</td>\n",
       "      <td>518 EVEREST BLVD</td>\n",
       "      <td>UDEMY</td>\n",
       "      <td>FL</td>\n",
       "      <td>12358.0</td>\n",
       "      <td>123789235.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELEANOR</td>\n",
       "      <td>P</td>\n",
       "      <td>TWINE</td>\n",
       "      <td>7878 SEVEN EIGHT</td>\n",
       "      <td>SMALL TOWN</td>\n",
       "      <td>LA</td>\n",
       "      <td>26916.0</td>\n",
       "      <td>148978105.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MICHELL</td>\n",
       "      <td>M</td>\n",
       "      <td>MENENDEZ</td>\n",
       "      <td>58 CLOUDLESS SKY WAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32156.0</td>\n",
       "      <td>203254687.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHARLES</td>\n",
       "      <td>F</td>\n",
       "      <td>KANE</td>\n",
       "      <td>794 BROKEN HOME AVE</td>\n",
       "      <td>ROSEBUD</td>\n",
       "      <td>PA</td>\n",
       "      <td>56465.0</td>\n",
       "      <td>489324789.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HOLDEN</td>\n",
       "      <td>K</td>\n",
       "      <td>CAULFIELD</td>\n",
       "      <td>79 IRONICAL DRIVE</td>\n",
       "      <td>INNOCENCE</td>\n",
       "      <td>PA</td>\n",
       "      <td>45687.0</td>\n",
       "      <td>102354548.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATTICUS</td>\n",
       "      <td>J</td>\n",
       "      <td>FINCH</td>\n",
       "      <td>1930 JUSTICE AVENUE</td>\n",
       "      <td>MAYCOMB</td>\n",
       "      <td>AL</td>\n",
       "      <td>36460.0</td>\n",
       "      <td>121611201.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KIT</td>\n",
       "      <td>H</td>\n",
       "      <td>SHARBER</td>\n",
       "      <td>PARADISE PLACE</td>\n",
       "      <td>ALMA</td>\n",
       "      <td>OR</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>485943315.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>MUAD'DIB</td>\n",
       "      <td>ATREIDES</td>\n",
       "      <td>314 PALACIAL ST</td>\n",
       "      <td>CALADAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>111555888.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>MAWDIB</td>\n",
       "      <td>ATRAYDEZ</td>\n",
       "      <td>PALACIAL ST</td>\n",
       "      <td>CALADAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>111555888.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>MAWDIB</td>\n",
       "      <td>ATRAYDEZ</td>\n",
       "      <td>314 PALACIAL STREET</td>\n",
       "      <td>CALIDAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>111555888.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MICHEAL</td>\n",
       "      <td>J</td>\n",
       "      <td>BURRY</td>\n",
       "      <td>20400 STEVENS CREEK BLVD</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>95014.0</td>\n",
       "      <td>158971324.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MIKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BURRY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158971324.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIRST    MIDDLE         LAST                   ADDRESS           CITY  \\\n",
       "0    HARVEY         B         MILK      1930 RECRUIT YOU AVE  SAN FRANCISCO   \n",
       "1    HARVEY         B         MILK      1930 RECRUIT YOU AVE             SF   \n",
       "2         H         B         MLLK      1930 RECRUIT YOU AVE             SF   \n",
       "3         H       NaN          NaN            1930 RECRUIT U            NaN   \n",
       "4      RICK         P      SANCHEZ               EARTH C-137         TACOMA   \n",
       "5     PYOTR         I  TCHAIKOVSKY           1840 N ST PETER       VOTKINSK   \n",
       "6    RUPERT         L       DONLEY          518 EVEREST BLVD          UDEMY   \n",
       "7   ELEANOR         P        TWINE          7878 SEVEN EIGHT     SMALL TOWN   \n",
       "8   MICHELL         M     MENENDEZ      58 CLOUDLESS SKY WAY            NaN   \n",
       "9   CHARLES         F         KANE       794 BROKEN HOME AVE        ROSEBUD   \n",
       "10   HOLDEN         K    CAULFIELD         79 IRONICAL DRIVE      INNOCENCE   \n",
       "11  ATTICUS         J        FINCH       1930 JUSTICE AVENUE        MAYCOMB   \n",
       "12      KIT         H      SHARBER            PARADISE PLACE           ALMA   \n",
       "13     PAUL  MUAD'DIB     ATREIDES           314 PALACIAL ST        CALADAN   \n",
       "14     PAUL    MAWDIB     ATRAYDEZ               PALACIAL ST        CALADAN   \n",
       "15     PAUL    MAWDIB     ATRAYDEZ       314 PALACIAL STREET        CALIDAN   \n",
       "16  MICHEAL         J        BURRY  20400 STEVENS CREEK BLVD      CUPERTINO   \n",
       "17     MIKE       NaN        BURRY                       NaN      CUPERTINO   \n",
       "\n",
       "   STATE      ZIP          SSN  Group Number  \n",
       "0     CA  18896.0  314159265.0            12  \n",
       "1     CA  18896.0  314159265.0            12  \n",
       "2     CA      NaN  314159265.0            11  \n",
       "3    NaN  18896.0          NaN            11  \n",
       "4     WA  98402.0  929601596.0            10  \n",
       "5     GA  11893.0  155633999.0             9  \n",
       "6     FL  12358.0  123789235.0             8  \n",
       "7     LA  26916.0  148978105.0             7  \n",
       "8    NaN  32156.0  203254687.0             6  \n",
       "9     PA  56465.0  489324789.0             5  \n",
       "10    PA  45687.0  102354548.0             4  \n",
       "11    AL  36460.0  121611201.0             3  \n",
       "12    OR  10002.0  485943315.0             2  \n",
       "13    CA  15587.0  111555888.0             1  \n",
       "14    CA  15587.0  111555888.0             1  \n",
       "15    CA  15587.0  111555888.0             1  \n",
       "16    CA  95014.0  158971324.0             0  \n",
       "17    CA      NaN  158971324.0             0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master.join( pd.DataFrame( { Groups.columns[0] : list( reversed( Groups[ Groups.columns[0] ].values.tolist() )) } ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notebook created by Austin Dial on 6/12/2019* <br>\n",
    "*Proof of Concept completed by Austin Dial on 6/21/2019* <br>\n",
    "*Development of Methods and Algorithm completed by Austin Dial on 7/1/2019*\n",
    "*Test data was updated by Austin Dial on 7/12/2019*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
